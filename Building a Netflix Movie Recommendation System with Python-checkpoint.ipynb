{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7f0b8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1420                Dynasty\n",
      "1535                   Evil\n",
      "1851                Godless\n",
      "1901              Greenleaf\n",
      "1925                  Gypsy\n",
      "1942                Halston\n",
      "1943    Halt and Catch Fire\n",
      "2008              Heartland\n",
      "2088              Hollywood\n",
      "2566             Knightfall\n",
      "Name: Title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"netflixData.csv\")\n",
    "\n",
    "# Data cleaning and preprocessing\n",
    "data = data[[\"Title\", \"Description\", \"Genres\", \"Content Type\"]]\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Using NLTK's SnowballStemmer and stopwords\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "stopwords_set = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = [word for word in text.split(' ') if word not in stopwords_set]\n",
    "    text = \" \".join(text)\n",
    "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "    return \" \".join(text)\n",
    "\n",
    "data[\"Genres\"] = data[\"Genres\"].apply(clean_text)\n",
    "data[\"Description\"] = data[\"Description\"].apply(clean_text)\n",
    "\n",
    "# Creating the TF-IDF matrix for the cleaned \"Genres\" column\n",
    "tfidf_vectorizer = text.TfidfVectorizer(stop_words=\"english\")\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data[\"Genres\"])\n",
    "\n",
    "# Calculating cosine similarity\n",
    "similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# Creating a function for movie recommendation\n",
    "def netflix_recommendation(title, similarity=similarity_matrix):\n",
    "    if title not in data[\"Title\"].values:\n",
    "        return \"Title not found in the dataset.\"\n",
    "\n",
    "    indices = pd.Series(data.index, index=data['Title']).drop_duplicates()\n",
    "    idx = indices[title]\n",
    "    similarity_scores = list(enumerate(similarity[idx]))\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "    similarity_scores = similarity_scores[1:11]  # Excluding the title itself\n",
    "    movie_indices = [i[0] for i in similarity_scores]\n",
    "    return data['Title'].iloc[movie_indices]\n",
    "\n",
    "# Test the recommendation function\n",
    "print(netflix_recommendation(\"Greenleaf\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7e5607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
